# Chapter 01 - 01. Parallel LLM training with Unsloth

This article took a record of training a Qwen2.5-32B LLM on a single GPU server with 8 H20 cards, 
following the guide of [Fine-Tuning DeepSeek R1 (Reasoning Model)](https://www.datacamp.com/tutorial/fine-tuning-deepseek-r1-reasoning-model).
